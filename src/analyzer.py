#!/usr/bin/env python3
"""AI ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ê¸° - OpenRouter ì—°ë™"""

import json
import os
from datetime import datetime, timezone, timedelta
from pathlib import Path

import requests
from openai import OpenAI

KST = timezone(timedelta(hours=9))
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

# ë¬´ë£Œ ëª¨ë¸ ìš°ì„ ìˆœìœ„ (fallback ìˆœì„œ)
FREE_MODELS = [
    "meta-llama/llama-3.2-3b-instruct:free",
    "google/gemma-3-1b-it:free",
    "mistralai/mistral-small-3.1-24b-instruct:free",
    "qwen/qwen3-4b:free",
]


def get_available_free_models(api_key: str) -> list[str]:
    """OpenRouter APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬´ë£Œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(
            f"{OPENROUTER_BASE_URL}/models",
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=10,
        )
        response.raise_for_status()
        models = response.json().get("data", [])

        # ë¬´ë£Œ ëª¨ë¸ í•„í„°ë§ (pricingì´ 0ì´ê±°ë‚˜ :free ì ‘ë¯¸ì‚¬)
        free_models = []
        for model in models:
            model_id = model.get("id", "")
            pricing = model.get("pricing", {})

            is_free = (
                ":free" in model_id
                or (pricing.get("prompt") == "0" and pricing.get("completion") == "0")
            )

            if is_free:
                free_models.append(model_id)

        return free_models
    except Exception as e:
        print(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def load_recent_data(hours: int = 24) -> list[dict]:
    """ìµœê·¼ Nì‹œê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    script_dir = Path(__file__).parent.parent
    log_dir = script_dir / "data" / "logs"

    all_posts = []
    now = datetime.now(KST)
    cutoff = now - timedelta(hours=hours)

    # ìµœê·¼ 2ì¼ì¹˜ íŒŒì¼ í™•ì¸ (24ì‹œê°„ì´ ë‚ ì§œë¥¼ ë„˜ì„ ìˆ˜ ìˆìŒ)
    for i in range(2):
        date = now - timedelta(days=i)
        log_file = log_dir / f"{date.strftime('%Y-%m-%d')}.json"

        if not log_file.exists():
            continue

        with open(log_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        for entry in data:
            collected_at = datetime.fromisoformat(entry["collected_at"])
            if collected_at >= cutoff:
                for post in entry["posts"]:
                    post["collected_at"] = entry["collected_at"]
                    all_posts.append(post)

    # ì¤‘ë³µ ì œê±° (ê°™ì€ ID)
    seen_ids = set()
    unique_posts = []
    for post in all_posts:
        if post["id"] not in seen_ids:
            seen_ids.add(post["id"])
            unique_posts.append(post)

    return unique_posts


def analyze_with_ai(posts: list[dict], model: str, client: OpenAI) -> str | None:
    """ì§€ì •ëœ ëª¨ë¸ë¡œ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    # ì œëª© ëª©ë¡ ì¤€ë¹„
    titles = [f"- {post['title']}" for post in posts[:100]]  # ìµœëŒ€ 100ê°œ
    titles_text = "\n".join(titles)

    prompt = f"""ë‹¤ìŒì€ ë½ë¿Œ ë¦´ë ˆì´ ê²Œì‹œíŒì—ì„œ ìµœê·¼ ìˆ˜ì§‘ëœ ê²Œì‹œë¬¼ ì œëª©ë“¤ì…ë‹ˆë‹¤.
ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ê³¼ SNS í™ë³´ ë¬¸êµ¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ìš”ì²­ì‚¬í•­
1. ì¸ê¸° í‚¤ì›Œë“œ: ìì£¼ ì–¸ê¸‰ë˜ëŠ” ë¸Œëœë“œ/ì„œë¹„ìŠ¤/ì´ë²¤íŠ¸ (ìƒìœ„ 5ê°œ, ê°„ë‹¨íˆ)
2. íŠ¸ë Œë“œ ìš”ì•½: í˜„ì¬ ì–´ë–¤ ì¢…ë¥˜ì˜ ì´ë²¤íŠ¸/í˜œíƒì´ ì£¼ë¡œ ì˜¬ë¼ì˜¤ëŠ”ì§€ (2-3ë¬¸ì¥)

## SNS í™ë³´ ë¬¸êµ¬
"ìŒ€ë¨¹" (ssalmug.com) ê´€ë ¨ X/ìŠ¤ë ˆë“œ ê²Œì‹œë¬¼ì„ 1ê°œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìŒ€ë¨¹ íŠ¹ì§• (1-2ê°œë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ):
- ë ˆí¼ëŸ´ ë§í¬ ë³µë¶™í•˜ë©´ AIê°€ ì•Œì•„ì„œ ë¶„ë¥˜í•´ì¤Œ
- ëˆ„ê°€ ë‚´ ë§í¬ ëˆ„ë¥´ë©´ ë‹µë°©í•˜ê¸° í¸í•¨
- ì˜¤ë˜ëœ ë§í¬ë„ ê³µì •í•˜ê²Œ ë…¸ì¶œë¨

ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  í†¤ì•¤ë§¤ë„ˆ:
- ì¹œêµ¬í•œí…Œ ì¹´í†¡í•˜ë“¯ í¸í•˜ê²Œ ì“°ê¸°
- "~í•´ë³´ì„¸ìš”", "~ìˆì–´ìš”" ê°™ì€ ê´‘ê³  ë§íˆ¬ ì ˆëŒ€ ê¸ˆì§€
- "~í•˜ë”ë¼", "~ì˜€ìŒ", "~ã…‹ã…‹", "~ì¸ë“¯" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ ì‚¬ìš©
- ì´ëª¨ì§€ëŠ” 1-2ê°œë§Œ, ì—†ì–´ë„ ë¨
- í•´ì‹œíƒœê·¸ 2ê°œ ì´í•˜
- 100ì ë‚´ì™¸ë¡œ ì§§ê²Œ
- ë§ˆì¹˜ ë³¸ì¸ì´ ì§ì ‘ ì¨ë³¸ í›„ê¸°ì²˜ëŸ¼

ì¢‹ì€ ì˜ˆì‹œ:
- "ìš”ì¦˜ ì¼€ì´ë±…í¬ ì´ë²¤íŠ¸ ìŒ€ë¨¹ì—ì„œ ë³´ê³  ì‹ ì²­í–ˆëŠ”ë° ë‹µë°©ë„ ë°”ë¡œ ë¨ ã…‹ã…‹"
- "ì¶”ì²œì¸ ë§í¬ ì •ë¦¬í•˜ê¸° ê·€ì°®ì•˜ëŠ”ë° ìŒ€ë¨¹ ì“°ë‹ˆê¹Œ ë³µë¶™ë§Œ í•˜ë©´ ì•Œì•„ì„œ ë¶„ë¥˜í•´ì¤Œ"
- "ì•Œëœ°í° ê°ˆì•„íƒ€ë ¤ê³  ìŒ€ë¨¹ ë“¤ì–´ê°”ë‹¤ê°€ ì¼€ë±… ëˆë‚˜ë¬´ë„ ë°œê²¬ ğŸ€"

ë‚˜ìœ ì˜ˆì‹œ (ì´ë ‡ê²Œ ì“°ì§€ ë§ ê²ƒ):
- "ìŒ€ë¨¹ì—ì„œ ë‹¤ì–‘í•œ í˜œíƒì„ ë§Œë‚˜ë³´ì„¸ìš”!"
- "ì¶”ì²œì¸ í”„ë¡œê·¸ë¨ê³¼ í•¨ê»˜ ì¦ê±°ìš´ ê²½í—˜ì„ í•´ë³´ì„¸ìš”~"

## ê²Œì‹œë¬¼ ì œëª© ({len(posts)}ê°œ)
{titles_text}

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model=model,
            max_tokens=1024,
            messages=[{"role": "user", "content": prompt}],
        )

        content = response.choices[0].message.content
        # ë¹ˆ ì‘ë‹µ ì²´í¬
        if content and content.strip():
            return content
        return None

    except Exception as e:
        print(f"  ëª¨ë¸ {model} ì‹¤íŒ¨: {e}")
        return None


def analyze_with_fallback(posts: list[dict]) -> tuple[str, str]:
    """ì—¬ëŸ¬ ë¬´ë£Œ ëª¨ë¸ì„ ì‹œë„í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤. (model, result) ë°˜í™˜"""
    api_key = os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        return "", "Error: OPENROUTER_API_KEY not set"

    client = OpenAI(
        base_url=OPENROUTER_BASE_URL,
        api_key=api_key,
    )

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë¬´ë£Œ ëª¨ë¸ ì¡°íšŒ
    available = get_available_free_models(api_key)
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë¬´ë£Œ ëª¨ë¸: {len(available)}ê°œ")

    # ìš°ì„ ìˆœìœ„ ëª¨ë¸ + ë™ì ìœ¼ë¡œ ë°œê²¬ëœ ëª¨ë¸
    models_to_try = []
    for model in FREE_MODELS:
        if model in available or not available:  # availableì´ ë¹„ë©´ ê·¸ëƒ¥ ì‹œë„
            models_to_try.append(model)

    # ì¶”ê°€ë¡œ ë°œê²¬ëœ ë¬´ë£Œ ëª¨ë¸ (ìš°ì„ ìˆœìœ„ì— ì—†ëŠ” ê²ƒë“¤)
    for model in available:
        if model not in models_to_try:
            models_to_try.append(model)

    # Fallback ì‹œë„
    for model in models_to_try[:5]:  # ìµœëŒ€ 5ê°œ ëª¨ë¸ ì‹œë„
        print(f"ëª¨ë¸ ì‹œë„: {model}")
        result = analyze_with_ai(posts, model, client)
        if result:
            return model, result

    return "", "Error: ëª¨ë“  ëª¨ë¸ì—ì„œ ë¶„ì„ ì‹¤íŒ¨"


def save_analysis(analysis: str, post_count: int, model: str) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    now = datetime.now(KST)
    date_str = now.strftime("%Y-%m-%d")

    script_dir = Path(__file__).parent.parent
    analysis_dir = script_dir / "data" / "analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)

    analysis_file = analysis_dir / f"{date_str}.json"

    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒˆ ë¦¬ìŠ¤íŠ¸
    if analysis_file.exists():
        with open(analysis_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    else:
        data = []

    entry = {
        "analyzed_at": now.isoformat(),
        "model": model,
        "post_count": post_count,
        "analysis": analysis,
    }
    data.append(entry)

    with open(analysis_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return str(analysis_file)


def main():
    print(f"[{datetime.now(KST).isoformat()}] íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘...")

    posts = load_recent_data(hours=24)
    print(f"ë¶„ì„ ëŒ€ìƒ ê²Œì‹œë¬¼: {len(posts)}ê°œ")

    if len(posts) < 5:
        print("ë¶„ì„í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 5ê°œ í•„ìš”)")
        return

    model, analysis = analyze_with_fallback(posts)

    print("\n=== ë¶„ì„ ê²°ê³¼ ===")
    if model:
        print(f"ì‚¬ìš© ëª¨ë¸: {model}")
    print(analysis)

    analysis_file = save_analysis(analysis, len(posts), model)
    print(f"\nì €ì¥ ì™„ë£Œ: {analysis_file}")


if __name__ == "__main__":
    main()
